{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c76db644-92c1-4921-813b-189e053b4afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import kmapper as km\n",
    "import pygeodesic\n",
    "import pygeodesic.geodesic as geodesic\n",
    "from scipy.spatial import distance_matrix\n",
    "import vtk\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa\n",
    "import scipy as sp\n",
    "import networkx as nx\n",
    "import random\n",
    "import math\n",
    "from networkx.algorithms import approximation\n",
    "from scipy.spatial.distance import cdist\n",
    "import open3d as o3d\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12330234-0f2b-446d-a5ea-171f3520ae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_off_file(filename):\n",
    "    with open(filename) as file:\n",
    "        lines = file.readlines()\n",
    "        lines = [line.strip() for line in lines]\n",
    "        \n",
    "        if lines[0] != \"OFF\":\n",
    "            raise ValueError('Not a valid OFF file')\n",
    "        n_vertices, n_faces, _ = map(int, lines[1].split())\n",
    "        vertices = [tuple(map(float, line.split())) for line in lines[2:2 + n_vertices]]\n",
    "        faces = [tuple(map(int, line.split()[1:])) for line in lines[2 + n_vertices: 2 + n_vertices + n_faces]]\n",
    "\n",
    "        # Create an array of vertex indices\n",
    "        vertex_indices = np.arange(n_vertices)\n",
    "        \n",
    "    return np.array(vertices), np.array(faces), vertex_indices\n",
    "\n",
    "vertices_1, faces_1, vertex_indices_1 = read_off_file('octopus1.off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b851432-a437-4021-9b06-6cce089a8e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "geoalg = geodesic.PyGeodesicAlgorithmExact(vertices_1, faces_1)\n",
    "D_1 = np.zeros((len(vertex_indices_1), len(vertex_indices_1)))\n",
    "for i in range(D_1.shape[0]):\n",
    "    source_indices = np.array([vertex_indices_1[i]]) \n",
    "    target_indices = np.array(vertex_indices_1)\n",
    "    distancess, best_source = geoalg.geodesicDistances(source_indices, target_indices)\n",
    "    D_1[i] = distancess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2020bf20-e378-4bd8-beff-1f754da55ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper_subsample(vertices, D, n_add = 10):\n",
    "\n",
    "    data = vertices\n",
    "    mapper = km.KeplerMapper(verbose=0)\n",
    "    \n",
    "    lens = mapper.fit_transform(data)\n",
    "    \n",
    "    graph = mapper.map(\n",
    "        lens,\n",
    "        data,\n",
    "        clusterer=sklearn.cluster.DBSCAN(eps=0.2, min_samples=3),\n",
    "        cover=km.Cover(n_cubes=60, perc_overlap=0.01),\n",
    "    )\n",
    "\n",
    "    nodes = list(graph['nodes'].keys())\n",
    "    \n",
    "    indexes = []\n",
    "    for i in range(len(nodes)):\n",
    "        tmp_idx = np.array(graph['nodes'][nodes[i]], int)\n",
    "        tmp_d = D[tmp_idx,:][:, tmp_idx].sum(axis=1)\n",
    "        indexes.append(tmp_idx[np.argmin(tmp_d)])\n",
    "\n",
    "    for i in range(n_add):\n",
    "        tmp_D = np.min(D[:,indexes], axis=1)\n",
    "        indexes.append(np.argmax(tmp_D))\n",
    "\n",
    "    print(\"%d points selected by Mapper with %d addition points\" %(len(nodes), n_add))\n",
    "\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "238156f8-50e8-443f-b9d1-9514014392f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134 points selected by Mapper with 10 addition points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/salovjade/anaconda3/lib/python3.10/site-packages/threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "idx_1 = mapper_subsample(vertices_1, D_1, n_add=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "703f429b-84e5-4583-8878-48cb41f6db01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 307,  556,  575,   53,  148,  414,   57,  956,   55,  339,  628,\n",
       "        971,  574,  909,    1,  602,  463, 1001,    0,   69,  358,  992,\n",
       "        218,   96,  906,  999,  582,  623,  914,  687,  621,  800,  354,\n",
       "        994,  831,  836,  616,  993,  352,  686,  834,  349,   81,  742,\n",
       "        997,  752,  608,   83,  547,  784,  987,  667,  362,  392,  249,\n",
       "        809,  984,  400,  629,  265,  102,  883,  716,  258,  355,  678,\n",
       "        160,  100,  581,  782,  931,  254,  459,  775,  882,  618,  756,\n",
       "        939,  159,  351,  700,  761,    7,  693,  759,  748,  416,  731,\n",
       "        268,  270,  136,  708,  818,  174,   17,  523,  263,  721,  703,\n",
       "        106,  634,  288,  114,  255,  165,  509,  198,   38,  367,  712,\n",
       "        276,   28,  105,  550,  475,  266,  727,  157,  172,  298,  156,\n",
       "        273,  668,  389,  421,  378,  747,  181,  204,  112,  554,  501,\n",
       "         33,  173,  935,  898,  948,   64,  597,  968,  947,  944,  328,\n",
       "        539])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highlightIndices1 = np.array(idx_1)\n",
    "highlightIndices1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d05b693d-50f6-49c3-9732-b71612a1b582",
   "metadata": {},
   "outputs": [],
   "source": [
    "#leg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d161a535-b019-4d9f-a9bc-2f772f222b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
       "        56,  57,  58, 123, 124, 125, 126, 127, 128, 129, 130, 131, 135,\n",
       "       196, 203, 206, 207, 209, 210, 211, 214, 215, 216, 218, 219, 220,\n",
       "       294, 299, 301, 302, 305, 306, 307, 309, 311, 312, 314, 316, 317,\n",
       "       318, 319, 407, 411, 413, 414, 417, 418, 419, 420, 422, 426, 427,\n",
       "       430, 431, 432, 436, 548, 549, 556, 560, 562, 563, 564, 565, 567,\n",
       "       568, 571, 572, 573, 574, 575, 578, 579, 582, 671, 681, 687, 689,\n",
       "       690, 745, 746, 749, 753, 794, 797, 800, 828])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geoalg = geodesic.PyGeodesicAlgorithmExact(vertices_1, faces_1)\n",
    "\n",
    "test, best = geoalg.geodesicDistances([550-1], [832-1])\n",
    "\n",
    "source_indices = np.array([550-1]) \n",
    "target_indices = np.array(vertex_indices_1)\n",
    "distancess, best_source = geoalg.geodesicDistances(source_indices, target_indices)\n",
    "\n",
    "target_indices = np.array(vertex_indices_1)\n",
    "\n",
    "indices_less_than_test_1 = target_indices[distancess < test]\n",
    "leg1 = indices_less_than_test_1.tolist()\n",
    "indices_less_than_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19622a6d-bad9-41be-9af6-a83f09273d57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#leg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b81e2159-95a6-4741-97ae-39b6f7edc668",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,  64,  65,  67,  69,  71,  72,  75,  76,  77,  78,  82, 137,\n",
       "       138, 140, 142, 146, 147, 148, 223, 227, 228, 230, 231, 232, 239,\n",
       "       240, 324, 325, 329, 331, 335, 336, 338, 339, 340, 341, 343, 345,\n",
       "       424, 434, 435, 440, 442, 445, 446, 451, 454, 455, 584, 585, 589,\n",
       "       590, 593, 596, 598, 599, 602, 603, 604, 605, 610, 611, 688, 765,\n",
       "       769, 771, 806, 834])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geoalg = geodesic.PyGeodesicAlgorithmExact(vertices_1, faces_1)\n",
    "\n",
    "test, best = geoalg.geodesicDistances([456-1], [841-1])\n",
    "\n",
    "source_indices = np.array([456-1]) \n",
    "target_indices = np.array(vertex_indices_1)\n",
    "distancess, best_source = geoalg.geodesicDistances(source_indices, target_indices)\n",
    "\n",
    "target_indices = np.array(vertex_indices_1)\n",
    "\n",
    "indices_less_than_test_2 = target_indices[distancess < test]\n",
    "leg2 = indices_less_than_test_2.tolist()\n",
    "indices_less_than_test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c86cc49a-33f4-4c06-9ead-3df26b9f3977",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#leg3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a8a45cf-988e-4d82-9e6e-7f0de60fe034",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 63,  73,  74,  80,  81,  83,  86,  87,  89,  92,  93,  94,  96,\n",
       "        98, 141, 144, 149, 151, 153, 221, 226, 237, 238, 241, 243, 245,\n",
       "       246, 247, 248, 321, 322, 328, 330, 333, 337, 344, 348, 349, 352,\n",
       "       353, 354, 356, 358, 438, 441, 448, 449, 453, 457, 460, 461, 462,\n",
       "       463, 464, 465, 466, 467, 470, 583, 600, 608, 609, 615, 616, 620,\n",
       "       621, 623, 625, 627, 628, 694, 695, 696, 697, 698, 770, 808, 809])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geoalg = geodesic.PyGeodesicAlgorithmExact(vertices_1, faces_1)\n",
    "\n",
    "test, best = geoalg.geodesicDistances([248-1], [842-1])\n",
    "\n",
    "source_indices = np.array([248-1]) \n",
    "target_indices = np.array(vertex_indices_1)\n",
    "distancess, best_source = geoalg.geodesicDistances(source_indices, target_indices)\n",
    "\n",
    "target_indices = np.array(vertex_indices_1)\n",
    "\n",
    "indices_less_than_test_3 = target_indices[distancess < test]\n",
    "leg3 = indices_less_than_test_3.tolist()\n",
    "indices_less_than_test_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21dfd91b-7d92-41f3-95ee-02f512c5c716",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#leg4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d780b02e-71e4-420d-bbb8-0f5f318a151e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 59,  60,  61,  62,  66,  68,  70,  79,  84,  85,  88,  90,  91,\n",
       "        95,  97,  99, 100, 101, 102, 132, 133, 134, 136, 139, 143, 145,\n",
       "       150, 152, 154, 213, 222, 224, 225, 229, 233, 234, 235, 236, 242,\n",
       "       244, 249, 320, 323, 326, 327, 332, 334, 342, 346, 347, 350, 351,\n",
       "       355, 357, 359, 360, 361, 362, 416, 428, 437, 439, 443, 444, 447,\n",
       "       450, 452, 456, 458, 459, 468, 469, 576, 586, 587, 588, 591, 592,\n",
       "       594, 595, 597, 601, 606, 607, 612, 613, 614, 617, 618, 619, 622,\n",
       "       624, 626, 629, 630, 631, 632, 683, 684, 692, 693, 755, 759, 760,\n",
       "       761, 795, 796])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geoalg = geodesic.PyGeodesicAlgorithmExact(vertices_1, faces_1)\n",
    "\n",
    "test, best = geoalg.geodesicDistances([250-1], [799-1])\n",
    "\n",
    "source_indices = np.array([250-1]) \n",
    "target_indices = np.array(vertex_indices_1)\n",
    "distancess, best_source = geoalg.geodesicDistances(source_indices, target_indices)\n",
    "\n",
    "target_indices = np.array(vertex_indices_1)\n",
    "\n",
    "indices_less_than_test_4 = target_indices[distancess < test]\n",
    "leg4 = indices_less_than_test_4.tolist()\n",
    "indices_less_than_test_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d654719f-665b-47d0-a036-26cfbd37cf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#leg5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f92024e8-d85f-4452-a633-67e0ad4ac13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([194, 195, 197, 198, 199, 200, 201, 202, 204, 205, 208, 212, 217,\n",
       "       287, 288, 293, 295, 296, 297, 298, 300, 303, 304, 308, 313, 402,\n",
       "       408, 409, 410, 412, 415, 421, 423, 433, 522, 525, 526, 527, 531,\n",
       "       532, 542, 544, 550, 551, 552, 554, 555, 561, 642, 643, 647, 655,\n",
       "       656, 657, 658, 660, 662, 663, 665, 668, 677, 682, 691, 703, 706,\n",
       "       707, 712, 718, 719, 720, 721, 723, 724, 726, 727, 728, 729, 730,\n",
       "       733, 734, 735, 740, 743, 747, 750, 754, 758, 766, 767, 780, 787,\n",
       "       789])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geoalg = geodesic.PyGeodesicAlgorithmExact(vertices_1, faces_1)\n",
    "\n",
    "test, best = geoalg.geodesicDistances([434-1], [819-1])\n",
    "\n",
    "source_indices = np.array([434-1]) \n",
    "target_indices = np.array(vertex_indices_1)\n",
    "distancess, best_source = geoalg.geodesicDistances(source_indices, target_indices)\n",
    "\n",
    "target_indices = np.array(vertex_indices_1)\n",
    "\n",
    "indices_less_than_test_5 = target_indices[distancess < test]\n",
    "leg5 = indices_less_than_test_5.tolist()\n",
    "indices_less_than_test_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7457797c-77cb-4b07-8669-99f7b796d380",
   "metadata": {},
   "outputs": [],
   "source": [
    "#leg6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebf5bcc3-c399-408f-a4b6-08bc1ffbd222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 22,  23,  24,  26,  27,  28,  30,  31,  32,  33,  37,  38,  39,\n",
       "        41, 108, 110, 111, 112, 113, 114, 118, 119, 121, 170, 171, 172,\n",
       "       173, 176, 178, 179, 180, 181, 182, 186, 188, 189, 262, 266, 267,\n",
       "       273, 275, 276, 277, 278, 279, 284, 377, 378, 381, 383, 384, 388,\n",
       "       389, 390, 391, 393, 396, 404, 491, 492, 493, 494, 495, 498, 499,\n",
       "       501, 502, 503, 504, 508, 509, 510, 512, 521, 523, 528, 634, 635,\n",
       "       636, 644, 646, 699, 702, 772, 778])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geoalg = geodesic.PyGeodesicAlgorithmExact(vertices_1, faces_1)\n",
    "\n",
    "test, best = geoalg.geodesicDistances([276-1], [775-1])\n",
    "\n",
    "source_indices = np.array([276-1]) \n",
    "target_indices = np.array(vertex_indices_1)\n",
    "distancess, best_source = geoalg.geodesicDistances(source_indices, target_indices)\n",
    "\n",
    "target_indices = np.array(vertex_indices_1)\n",
    "\n",
    "indices_less_than_test_6 = target_indices[distancess < test]\n",
    "leg6 = indices_less_than_test_6.tolist()\n",
    "indices_less_than_test_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60520680-4da4-4986-9944-860dfb1f4035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#leg7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "655f7c4a-1270-4aef-afe3-627e0fba3385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5,   8,   9,  10,  14,  15,  16,  17,  25,  29,  36, 103, 105,\n",
       "       106, 109, 115, 117, 156, 157, 158, 161, 162, 163, 165, 174, 175,\n",
       "       177, 183, 187, 251, 252, 253, 255, 257, 260, 261, 263, 264, 268,\n",
       "       270, 280, 281, 283, 365, 366, 367, 370, 372, 374, 379, 385, 386,\n",
       "       399, 405, 475, 476, 479, 480, 481, 483, 484, 485, 488, 496, 497,\n",
       "       505, 506, 514, 515, 518, 524, 537, 633, 639, 700, 701, 711, 773,\n",
       "       775, 776, 783])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geoalg = geodesic.PyGeodesicAlgorithmExact(vertices_1, faces_1)\n",
    "\n",
    "test, best = geoalg.geodesicDistances([104-1], [818-1])\n",
    "\n",
    "source_indices = np.array([104-1]) \n",
    "target_indices = np.array(vertex_indices_1)\n",
    "distancess, best_source = geoalg.geodesicDistances(source_indices, target_indices)\n",
    "\n",
    "target_indices = np.array(vertex_indices_1)\n",
    "\n",
    "indices_less_than_test_7 = target_indices[distancess < test]\n",
    "leg7 = indices_less_than_test_7.tolist()\n",
    "indices_less_than_test_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ff1bd64-29c2-4f81-99c9-1e55d049b6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#leg8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb02de44-9dae-49f8-8406-210d180c28c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3,   4,   6,   7,  11,  12,  13,  18,  19,  20,  21,  34,  35,\n",
       "        40,  42,  43,  44, 104, 107, 116, 120, 122, 155, 159, 160, 164,\n",
       "       166, 167, 168, 169, 184, 185, 190, 191, 192, 193, 250, 254, 256,\n",
       "       258, 259, 265, 269, 271, 272, 274, 282, 286, 289, 290, 292, 363,\n",
       "       364, 368, 369, 371, 373, 375, 376, 380, 382, 387, 392, 394, 395,\n",
       "       397, 400, 401, 406, 471, 472, 473, 474, 477, 478, 482, 486, 487,\n",
       "       489, 490, 500, 507, 511, 513, 516, 517, 519, 520, 529, 530, 640,\n",
       "       641, 649, 704, 705, 717, 737, 785, 788, 821, 822])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geoalg = geodesic.PyGeodesicAlgorithmExact(vertices_1, faces_1)\n",
    "\n",
    "test, best = geoalg.geodesicDistances([4-1], [845-1])\n",
    "\n",
    "source_indices = np.array([4-1]) \n",
    "target_indices = np.array(vertex_indices_1)\n",
    "distancess, best_source = geoalg.geodesicDistances(source_indices, target_indices)\n",
    "\n",
    "target_indices = np.array(vertex_indices_1)\n",
    "\n",
    "indices_less_than_test_8 = target_indices[distancess < test]\n",
    "leg8 = indices_less_than_test_8.tolist()\n",
    "indices_less_than_test_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5804f0a7-e0e5-4baa-8683-19dcdc99ac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcce7b69-31be-4436-8437-4705dc98b208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 285,  291,  310,  315,  398,  403,  425,  429,  533,  534,  535,\n",
       "        536,  538,  539,  540,  541,  543,  545,  546,  547,  553,  557,\n",
       "        558,  559,  566,  569,  570,  577,  580,  581,  637,  638,  645,\n",
       "        648,  650,  651,  652,  653,  654,  659,  661,  664,  666,  667,\n",
       "        669,  670,  672,  673,  674,  675,  676,  678,  679,  680,  685,\n",
       "        686,  708,  709,  710,  713,  714,  715,  716,  722,  725,  731,\n",
       "        732,  736,  738,  739,  741,  742,  744,  748,  751,  752,  756,\n",
       "        757,  762,  763,  764,  768,  774,  777,  779,  781,  782,  784,\n",
       "        786,  790,  791,  792,  793,  798,  799,  801,  802,  803,  804,\n",
       "        805,  807,  810,  811,  812,  813,  814,  815,  816,  817,  818,\n",
       "        819,  820,  823,  824,  825,  826,  827,  829,  830,  831,  832,\n",
       "        833,  835,  836,  837,  838,  839,  840,  841,  842,  843,  844,\n",
       "        845,  846,  847,  848,  849,  850,  851,  852,  853,  854,  855,\n",
       "        856,  857,  858,  859,  860,  861,  862,  863,  864,  865,  866,\n",
       "        867,  868,  869,  870,  871,  872,  873,  874,  875,  876,  877,\n",
       "        878,  879,  880,  881,  882,  883,  884,  885,  886,  887,  888,\n",
       "        889,  890,  891,  892,  893,  894,  895,  896,  897,  898,  899,\n",
       "        900,  901,  902,  903,  904,  905,  906,  907,  908,  909,  910,\n",
       "        911,  912,  913,  914,  915,  916,  917,  918,  919,  920,  921,\n",
       "        922,  923,  924,  925,  926,  927,  928,  929,  930,  931,  932,\n",
       "        933,  934,  935,  936,  937,  938,  939,  940,  941,  942,  943,\n",
       "        944,  945,  946,  947,  948,  949,  950,  951,  952,  953,  954,\n",
       "        955,  956,  957,  958,  959,  960,  961,  962,  963,  964,  965,\n",
       "        966,  967,  968,  969,  970,  971,  972,  973,  974,  975,  976,\n",
       "        977,  978,  979,  980,  981,  982,  983,  984,  985,  986,  987,\n",
       "        988,  989,  990,  991,  992,  993,  994,  995,  996,  997,  998,\n",
       "        999, 1000, 1001])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = leg1 + leg2 + leg3 + leg4 + leg5 + leg6 + leg7 + leg8\n",
    "body = [item for item in vertex_indices_1 if item not in combined]\n",
    "\n",
    "indices_less_than_test_9 = np.array(body)\n",
    "indices_less_than_test_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73f9ad36-a32f-46dd-98dd-d853045d6115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import idx_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd323d1e-e834-491f-b1df-f71fb0bfae4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 points selected by Mapper with 10 addition points\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([925, 841, 843, 817, 818, 776, 773, 753, 684, 682, 983, 614, 957,\n",
       "       579, 448, 934, 208, 510, 874, 169, 421, 587, 889, 106, 419, 835,\n",
       "       105, 852, 882, 105, 794, 125, 770, 881, 124, 418, 699, 168, 480,\n",
       "       416, 976, 424, 356, 314, 381, 955, 230, 404, 182, 790, 812, 166,\n",
       "       379, 164, 162, 458, 853, 177, 437, 250, 375, 655, 830, 244, 238,\n",
       "       242, 805, 868, 192, 378, 865, 189, 220, 821, 133, 240, 849, 115,\n",
       "       139, 333, 810, 119, 272,  56,  99, 436,  63,  78, 200, 468,  55,\n",
       "        71, 273, 493,  61, 159, 465,  60, 143, 492,  59, 123, 528,  25,\n",
       "        39,   8,  30,   1,   0,  20,   6,  21,  16,  12,  11,   2,   4,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertices_2, faces_2, vertex_indices_2 = read_off_file('octopus2.off')\n",
    "\n",
    "geoalg = geodesic.PyGeodesicAlgorithmExact(vertices_2, faces_2)\n",
    "D_2 = np.zeros((len(vertex_indices_2), len(vertex_indices_2)))\n",
    "for i in range(D_2.shape[0]):\n",
    "    source_indices = np.array([vertex_indices_2[i]]) \n",
    "    target_indices = np.array(vertex_indices_2)\n",
    "    distancess, best_source = geoalg.geodesicDistances(source_indices, target_indices)\n",
    "    D_1[i] = distancess\n",
    "    \n",
    "idx_2 = mapper_subsample(vertices_2, D_2, n_add=10)  \n",
    "\n",
    "highlightIndices2 = np.array(idx_2)\n",
    "highlightIndices2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09f9f301-17bb-409f-86f7-29eefa3bc437",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign legs matching from each P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb261e71-9c74-49c2-9121-47703e8b87f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.05 Sum of the matrix: 0      0.00000\n",
      "1      0.00000\n",
      "2      0.00000\n",
      "3      0.00000\n",
      "4      0.00000\n",
      "        ...   \n",
      "122    0.00121\n",
      "123    0.00121\n",
      "124    0.00121\n",
      "125    0.00121\n",
      "126    0.00121\n",
      "Length: 127, dtype: float64\n",
      "Threshold: 0.1 Sum of the matrix: 0      0.000000\n",
      "1      0.000000\n",
      "2      0.000000\n",
      "3      0.007874\n",
      "4      0.006957\n",
      "         ...   \n",
      "122    0.000000\n",
      "123    0.000000\n",
      "124    0.000000\n",
      "125    0.000000\n",
      "126    0.000000\n",
      "Length: 127, dtype: float64\n",
      "Threshold: 0.2 Sum of the matrix: 0      0.000000\n",
      "1      0.000000\n",
      "2      0.002318\n",
      "3      0.004689\n",
      "4      0.007874\n",
      "         ...   \n",
      "122    0.000000\n",
      "123    0.000000\n",
      "124    0.000000\n",
      "125    0.000000\n",
      "126    0.000000\n",
      "Length: 127, dtype: float64\n",
      "Threshold: 0.3 Sum of the matrix: 0      0.000000\n",
      "1      0.000000\n",
      "2      0.001590\n",
      "3      0.003598\n",
      "4      0.007330\n",
      "         ...   \n",
      "122    0.000000\n",
      "123    0.000000\n",
      "124    0.000000\n",
      "125    0.000000\n",
      "126    0.000000\n",
      "Length: 127, dtype: float64\n",
      "Threshold: 0.4 Sum of the matrix: 0      0.000000\n",
      "1      0.000000\n",
      "2      0.000876\n",
      "3      0.002610\n",
      "4      0.005920\n",
      "         ...   \n",
      "122    0.001576\n",
      "123    0.001576\n",
      "124    0.001576\n",
      "125    0.001576\n",
      "126    0.001576\n",
      "Length: 127, dtype: float64\n",
      "Threshold: 0.5 Sum of the matrix: 0      0.000000\n",
      "1      0.000000\n",
      "2      0.001005\n",
      "3      0.002836\n",
      "4      0.006588\n",
      "         ...   \n",
      "122    0.001698\n",
      "123    0.001698\n",
      "124    0.001698\n",
      "125    0.001698\n",
      "126    0.001698\n",
      "Length: 127, dtype: float64\n",
      "Threshold: 0.6 Sum of the matrix: 0      0.000444\n",
      "1      0.000554\n",
      "2      0.001618\n",
      "3      0.002759\n",
      "4      0.003721\n",
      "         ...   \n",
      "122    0.003083\n",
      "123    0.003083\n",
      "124    0.003083\n",
      "125    0.003083\n",
      "126    0.003083\n",
      "Length: 127, dtype: float64\n",
      "Threshold: 0.7 Sum of the matrix: 0      0.000000\n",
      "1      0.000000\n",
      "2      0.000000\n",
      "3      0.000000\n",
      "4      0.000000\n",
      "         ...   \n",
      "122    0.003694\n",
      "123    0.003694\n",
      "124    0.003694\n",
      "125    0.003694\n",
      "126    0.003694\n",
      "Length: 127, dtype: float64\n",
      "Threshold: 0.8 Sum of the matrix: 0      0.000000\n",
      "1      0.000000\n",
      "2      0.000000\n",
      "3      0.000000\n",
      "4      0.000000\n",
      "         ...   \n",
      "122    0.003633\n",
      "123    0.003633\n",
      "124    0.003633\n",
      "125    0.003633\n",
      "126    0.003633\n",
      "Length: 127, dtype: float64\n",
      "Threshold: 0.9 Sum of the matrix: 0      0.000000\n",
      "1      0.000000\n",
      "2      0.000000\n",
      "3      0.000000\n",
      "4      0.000000\n",
      "         ...   \n",
      "122    0.003921\n",
      "123    0.003921\n",
      "124    0.003921\n",
      "125    0.003921\n",
      "126    0.003921\n",
      "Length: 127, dtype: float64\n",
      "Threshold: 1.0 Sum of the matrix: 0      0.000000\n",
      "1      0.000000\n",
      "2      0.000000\n",
      "3      0.000000\n",
      "4      0.000000\n",
      "         ...   \n",
      "122    0.003849\n",
      "123    0.003849\n",
      "124    0.003849\n",
      "125    0.003849\n",
      "126    0.003849\n",
      "Length: 127, dtype: float64\n",
      "Threshold: 1.1 Sum of the matrix: 0      0.000000\n",
      "1      0.000000\n",
      "2      0.000000\n",
      "3      0.000000\n",
      "4      0.000000\n",
      "         ...   \n",
      "122    0.003687\n",
      "123    0.003687\n",
      "124    0.003687\n",
      "125    0.003687\n",
      "126    0.003687\n",
      "Length: 127, dtype: float64\n",
      "Threshold: 1.2 Sum of the matrix: 0      0.000000\n",
      "1      0.000000\n",
      "2      0.000000\n",
      "3      0.000000\n",
      "4      0.000000\n",
      "         ...   \n",
      "122    0.002097\n",
      "123    0.002097\n",
      "124    0.002097\n",
      "125    0.002097\n",
      "126    0.002097\n",
      "Length: 127, dtype: float64\n",
      "Threshold: 1.3 Sum of the matrix: 0      0.000000\n",
      "1      0.000000\n",
      "2      0.000000\n",
      "3      0.000000\n",
      "4      0.007874\n",
      "         ...   \n",
      "122    0.000000\n",
      "123    0.000000\n",
      "124    0.000000\n",
      "125    0.000000\n",
      "126    0.000000\n",
      "Length: 127, dtype: float64\n",
      "Threshold: 1.4 Sum of the matrix: 0      0.000000\n",
      "1      0.000000\n",
      "2      0.000000\n",
      "3      0.007874\n",
      "4      0.007874\n",
      "         ...   \n",
      "122    0.000000\n",
      "123    0.000000\n",
      "124    0.000000\n",
      "125    0.000000\n",
      "126    0.000000\n",
      "Length: 127, dtype: float64\n",
      "Threshold: 1.5 Sum of the matrix: 0      0.002822\n",
      "1      0.003193\n",
      "2      0.007874\n",
      "3      0.007874\n",
      "4      0.007874\n",
      "         ...   \n",
      "122    0.000570\n",
      "123    0.000570\n",
      "124    0.000570\n",
      "125    0.000570\n",
      "126    0.000570\n",
      "Length: 127, dtype: float64\n",
      "Threshold: 1.6 Sum of the matrix: 0      0.000000e+00\n",
      "1      4.423000e-07\n",
      "2      2.084700e-06\n",
      "3      1.354990e-05\n",
      "4      9.258920e-05\n",
      "           ...     \n",
      "122    7.874016e-03\n",
      "123    7.874016e-03\n",
      "124    7.874016e-03\n",
      "125    7.874016e-03\n",
      "126    7.874016e-03\n",
      "Length: 127, dtype: float64\n",
      "Threshold: 1.7 Sum of the matrix: 0      0.000077\n",
      "1      0.000096\n",
      "2      0.000229\n",
      "3      0.000512\n",
      "4      0.002045\n",
      "         ...   \n",
      "122    0.007874\n",
      "123    0.007874\n",
      "124    0.007874\n",
      "125    0.007874\n",
      "126    0.007874\n",
      "Length: 127, dtype: float64\n",
      "Threshold: 1.8 Sum of the matrix: 0      0.000000\n",
      "1      0.000000\n",
      "2      0.000000\n",
      "3      0.000000\n",
      "4      0.000000\n",
      "         ...   \n",
      "122    0.007874\n",
      "123    0.007874\n",
      "124    0.007874\n",
      "125    0.007874\n",
      "126    0.007874\n",
      "Length: 127, dtype: float64\n",
      "Threshold: 1.9 Sum of the matrix: 0      0.000000\n",
      "1      0.000000\n",
      "2      0.000000\n",
      "3      0.000000\n",
      "4      0.007874\n",
      "         ...   \n",
      "122    0.007874\n",
      "123    0.007874\n",
      "124    0.007874\n",
      "125    0.007874\n",
      "126    0.007874\n",
      "Length: 127, dtype: float64\n",
      "Threshold: 2.0 Sum of the matrix: 0      0.000000\n",
      "1      0.006944\n",
      "2      0.007874\n",
      "3      0.007874\n",
      "4      0.007874\n",
      "         ...   \n",
      "122    0.007874\n",
      "123    0.007874\n",
      "124    0.007874\n",
      "125    0.007874\n",
      "126    0.007874\n",
      "Length: 127, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "thresholds = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0]\n",
    "\n",
    "\n",
    "\n",
    "def find_connected_indices(subset_highlightIndices1, matrix, highlightIndices1, highlightIndices2):\n",
    "    connected_indices_subset = []\n",
    "    for i, index1 in enumerate(highlightIndices1):\n",
    "        if index1 in subset_highlightIndices1:\n",
    "            # Find the index of the max value in the row\n",
    "            j = matrix.iloc[i].idxmax()\n",
    "            \n",
    "            # Check if the max value is not zero\n",
    "            if matrix.iat[i, j] != 0:\n",
    "                connected_indices_subset.append(highlightIndices2[j])\n",
    "    return np.array(connected_indices_subset)\n",
    "\n",
    "\n",
    "for threshold in thresholds:    \n",
    "    file_path = f'P_octopus_1203_{threshold}.csv'\n",
    "    matrix_df = pd.read_csv(file_path, header=None)\n",
    "    matrix_sum = np.sum(matrix_df)\n",
    "\n",
    "    print(\"Threshold:\", threshold, \"Sum of the matrix:\", matrix_sum)\n",
    "    \n",
    "    # Define the index arrays as provided by the user\n",
    "    highlightIndices1 = idx_1 \n",
    "    highlightIndices2 = idx_2\n",
    "\n",
    "    ## Find non-zero entries in the matrix and map them to the corresponding indices in highlightIndices1 and highlightIndices2\n",
    "    #connected_indices = []\n",
    "    #for i in range(matrix_df.shape[0]):  # Loop over rows\n",
    "       # for j in range(matrix_df.shape[1]):  # Loop over columns\n",
    "          #  if matrix_df.iat[i, j] != 0:  # Check if the matrix element is non-zero\n",
    "           #     connected_indices.append((highlightIndices1[i], highlightIndices2[j]))  # Store the connected indices\n",
    "\n",
    "    # Find the column with the largest value in each row and map them\n",
    "    connected_indices = []\n",
    "    for i in range(matrix_df.shape[0]):  # Loop over rows\n",
    "        # Find the index of the max value in the row\n",
    "        j = matrix_df.iloc[i].idxmax()\n",
    "\n",
    "        # Map and store the indices if the max value is not zero\n",
    "        if matrix_df.iat[i, j] != 0:\n",
    "            connected_indices.append((highlightIndices1[i], highlightIndices2[j]))\n",
    "\n",
    "    ## Find the row with the largest value in each column and map them\n",
    "    #connected_indices = []\n",
    "    #for j in range(matrix_df.shape[1]):  # Loop over columns\n",
    "       # # Find the index of the max value in the column\n",
    "       # i = matrix_df.iloc[:, j].idxmax()\n",
    "\n",
    "       # # Map and store the indices if the max value is not zero\n",
    "       # if matrix_df.iat[i, j] != 0:\n",
    "          #  connected_indices.append((highlightIndices1[i], highlightIndices2[j]))\n",
    "\n",
    "    # Display the connected indices\n",
    "    # connected_indices\n",
    "    \n",
    "    # Convert connected_indices to a DataFrame\n",
    "    connected_indices_df = pd.DataFrame(connected_indices, columns=['Index1', 'Index2'])\n",
    "\n",
    "    first_column = connected_indices_df['Index1']\n",
    "\n",
    "    # Optionally, convert it to a numpy array\n",
    "    sub_highlightIndices1 = first_column.to_numpy()\n",
    "    \n",
    "    second_column = connected_indices_df['Index2']\n",
    "\n",
    "    # Optionally, convert it to a numpy array\n",
    "    sub_highlightIndices2 = second_column.to_numpy()\n",
    "    \n",
    "    # Example usage:\n",
    "    sub_highlightIndices1_leg1 = np.intersect1d(sub_highlightIndices1,indices_less_than_test_1)\n",
    "    # Read from matlab first, remember -1 \n",
    "    \n",
    "    sub_highlightIndices2_leg1 = find_connected_indices(sub_highlightIndices1_leg1, matrix_df, highlightIndices1, highlightIndices2)\n",
    "    \n",
    "    sub_highlightIndices1_leg2 = np.intersect1d(sub_highlightIndices1,indices_less_than_test_2)\n",
    "\n",
    "    # Read from matlab first, remember -1 \n",
    "    sub_highlightIndices2_leg2 = find_connected_indices(sub_highlightIndices1_leg2, matrix_df, highlightIndices1, highlightIndices2)\n",
    "\n",
    "    \n",
    "    sub_highlightIndices1_leg3 = np.intersect1d(sub_highlightIndices1,indices_less_than_test_3)\n",
    "\n",
    "    # Read from matlab first, remember -1 \n",
    "    sub_highlightIndices2_leg3 = find_connected_indices(sub_highlightIndices1_leg3, matrix_df, highlightIndices1, highlightIndices2)\n",
    "\n",
    "    \n",
    "    sub_highlightIndices1_leg4 = np.intersect1d(sub_highlightIndices1,indices_less_than_test_4)\n",
    "\n",
    "    # Read from matlab first, remember -1 \n",
    "    sub_highlightIndices2_leg4 = find_connected_indices(sub_highlightIndices1_leg4, matrix_df, highlightIndices1, highlightIndices2)\n",
    "\n",
    "    \n",
    "    sub_highlightIndices1_leg5 = np.intersect1d(sub_highlightIndices1,indices_less_than_test_5)\n",
    "\n",
    "    # Read from matlab first, remember -1 \n",
    "    sub_highlightIndices2_leg5 = find_connected_indices(sub_highlightIndices1_leg5, matrix_df, highlightIndices1, highlightIndices2)\n",
    "\n",
    "    \n",
    "    sub_highlightIndices1_leg6 = np.intersect1d(sub_highlightIndices1,indices_less_than_test_6)\n",
    "\n",
    "    # Read from matlab first, remember -1 \n",
    "    sub_highlightIndices2_leg6 = find_connected_indices(sub_highlightIndices1_leg6, matrix_df, highlightIndices1, highlightIndices2)\n",
    "\n",
    "    \n",
    "    sub_highlightIndices1_leg7 = np.intersect1d(sub_highlightIndices1,indices_less_than_test_7)\n",
    "\n",
    "    # Read from matlab first, remember -1 \n",
    "    sub_highlightIndices2_leg7 = find_connected_indices(sub_highlightIndices1_leg7, matrix_df, highlightIndices1, highlightIndices2)\n",
    "\n",
    "    \n",
    "    sub_highlightIndices1_leg8 = np.intersect1d(sub_highlightIndices1,indices_less_than_test_8)\n",
    "\n",
    "    # Read from matlab first, remember -1 \n",
    "    sub_highlightIndices2_leg8 = find_connected_indices(sub_highlightIndices1_leg8, matrix_df, highlightIndices1, highlightIndices2)\n",
    "\n",
    "    \n",
    "    sub_highlightIndices1_body = np.intersect1d(sub_highlightIndices1,indices_less_than_test_9)\n",
    "\n",
    "    # Read from matlab first, remember -1 \n",
    "    sub_highlightIndices2_body = find_connected_indices(sub_highlightIndices1_body, matrix_df, highlightIndices1, highlightIndices2)\n",
    "\n",
    "    \n",
    "    # save data\n",
    "    data_to_save = {\n",
    "    \"sub_highlightIndices1\": sub_highlightIndices1.tolist(),\n",
    "    \"sub_highlightIndices2\": sub_highlightIndices2.tolist(), \n",
    "    \"sub_highlightIndices1_body\": sub_highlightIndices1_body.tolist(),\n",
    "    \"sub_highlightIndices2_body\": sub_highlightIndices2_body.tolist(),\n",
    "    \"sub_highlightIndices1_leg1\": sub_highlightIndices1_leg1.tolist(),\n",
    "    \"sub_highlightIndices2_leg1\": sub_highlightIndices2_leg1.tolist(),\n",
    "    \"sub_highlightIndices1_leg2\": sub_highlightIndices1_leg2.tolist(),\n",
    "    \"sub_highlightIndices2_leg2\": sub_highlightIndices2_leg2.tolist(),\n",
    "    \"sub_highlightIndices1_leg3\": sub_highlightIndices1_leg3.tolist(),\n",
    "    \"sub_highlightIndices2_leg3\": sub_highlightIndices2_leg3.tolist(),\n",
    "    \"sub_highlightIndices1_leg4\": sub_highlightIndices1_leg4.tolist(),\n",
    "    \"sub_highlightIndices2_leg4\": sub_highlightIndices2_leg4.tolist(),\n",
    "    \"sub_highlightIndices1_leg5\": sub_highlightIndices1_leg5.tolist(),\n",
    "    \"sub_highlightIndices2_leg5\": sub_highlightIndices2_leg5.tolist(),\n",
    "    \"sub_highlightIndices1_leg6\": sub_highlightIndices1_leg6.tolist(),\n",
    "    \"sub_highlightIndices2_leg6\": sub_highlightIndices2_leg6.tolist(),\n",
    "    \"sub_highlightIndices1_leg7\": sub_highlightIndices1_leg7.tolist(),\n",
    "    \"sub_highlightIndices2_leg7\": sub_highlightIndices2_leg7.tolist(),\n",
    "    \"sub_highlightIndices1_leg8\": sub_highlightIndices1_leg8.tolist(),\n",
    "    \"sub_highlightIndices2_leg8\": sub_highlightIndices2_leg8.tolist(),\n",
    "    }\n",
    "\n",
    "    # Save as JSON file\n",
    "    filename = f'highlight_indices_{threshold}.json'\n",
    "    with open(filename, 'w') as outfile:\n",
    "        json.dump(data_to_save, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171f5157-85a5-4278-a89a-c6584dc37f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test sum P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22081e7a-ab01-46df-ba27-95b04c99bc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rho: 0.05 Sum of the matrix: 0.1259295708\n",
      "rho: 0.1 Sum of the matrix: 0.3435586171\n",
      "rho: 0.2 Sum of the matrix: 0.4913057736\n",
      "rho: 0.3 Sum of the matrix: 0.5918088347999999\n",
      "rho: 0.4 Sum of the matrix: 0.6765638666000001\n",
      "rho: 0.5 Sum of the matrix: 0.6992563436\n",
      "rho: 0.6 Sum of the matrix: 0.7603893277\n",
      "rho: 0.7 Sum of the matrix: 0.7507108502000001\n",
      "rho: 0.8 Sum of the matrix: 0.6859142612\n",
      "rho: 0.9 Sum of the matrix: 0.7048884516999999\n",
      "rho: 1.0 Sum of the matrix: 0.68591426\n",
      "rho: 1.1 Sum of the matrix: 0.7271434824999999\n",
      "rho: 1.2 Sum of the matrix: 0.7123250195\n",
      "rho: 1.3 Sum of the matrix: 0.7696337055\n",
      "rho: 1.4 Sum of the matrix: 0.8114913248\n",
      "rho: 1.5 Sum of the matrix: 0.8319506028\n",
      "rho: 1.6 Sum of the matrix: 0.8211395309\n",
      "rho: 1.7 Sum of the matrix: 0.8670166097\n",
      "rho: 1.8 Sum of the matrix: 0.8832567689999999\n",
      "rho: 1.9 Sum of the matrix: 0.956911624\n",
      "rho: 2.0 Sum of the matrix: 0.9842519446999999\n"
     ]
    }
   ],
   "source": [
    "for threshold in thresholds:\n",
    "    filename = f'P_octopus_1203_{threshold}.csv'\n",
    "    df = pd.read_csv(filename)\n",
    "    matrix = df.values\n",
    "    matrix_sum = np.sum(matrix)\n",
    "    print(\"rho:\", threshold, \"Sum of the matrix:\", matrix_sum)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e6971d-6979-445c-a88d-3981097919f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905957f0-028a-4d94-89ff-e2bbece24bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
